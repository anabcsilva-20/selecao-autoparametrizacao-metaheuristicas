{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d6ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MH  NJOBS  NMACHINES  CMAXOPT OBJFUNC  CMAX  TIMEEXEC  NUMGEN  NUMPART  \\\n",
      "0    GA     10          5      655      WT   837     10.62   100.0      NaN   \n",
      "1    GA     10         10      887      WT  1504     13.50   100.0      NaN   \n",
      "2    GA     10         10      887      WT  1653     13.71   100.0      NaN   \n",
      "3    GA     15          5      890      WT  1020     27.41   100.0      NaN   \n",
      "4    GA     10         10      899      WT  1501      9.55   100.0      NaN   \n",
      "..   ..    ...        ...      ...     ...   ...       ...     ...      ...   \n",
      "550  SA     50         10     2972    Cmax  5191      7.55     NaN      NaN   \n",
      "551  SA     50         10     3104    Cmax  5495      5.27     NaN      NaN   \n",
      "552  SA     10         10      848      WT  1037      0.22     NaN      NaN   \n",
      "553  SA     10         10      943      WT  1078      0.27     NaN      NaN   \n",
      "554  SA     10         10      944      WT  1411      0.24     NaN      NaN   \n",
      "\n",
      "     NUMITERA  INITTEMP  NUMITERAK  SA_STOPCRIT  TABULISTLEN  TS_STOPCRIT  \n",
      "0         NaN       NaN        NaN          NaN          NaN          NaN  \n",
      "1         NaN       NaN        NaN          NaN          NaN          NaN  \n",
      "2         NaN       NaN        NaN          NaN          NaN          NaN  \n",
      "3         NaN       NaN        NaN          NaN          NaN          NaN  \n",
      "4         NaN       NaN        NaN          NaN          NaN          NaN  \n",
      "..        ...       ...        ...          ...          ...          ...  \n",
      "550       NaN      15.0       31.0        190.0          NaN          NaN  \n",
      "551       NaN      15.0       29.0        188.0          NaN          NaN  \n",
      "552       NaN      14.0       13.0         33.0          NaN          NaN  \n",
      "553       NaN      14.0       13.0         33.0          NaN          NaN  \n",
      "554       NaN      14.0       15.0         38.0          NaN          NaN  \n",
      "\n",
      "[555 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "#MODELO DE REGRESSÃO GERAL - MODELO DE AFINAÇÃO DOS PARÂMETROS DAS META-HEURÍSTICAS ------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import xlwings as xw\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "#EXCEL - CAMINHO DO FICHEIRO\n",
    "file_path = r\"D:\\Documentos\\...\\DataSet_Regressão_ModeloGeral.xlsx\"\n",
    "dados_problema= pd.read_excel(file_path)\n",
    "print (dados_problema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec1a83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     MH     vetor_parametros\n",
      "0    GA        [100.0, 0, 0]\n",
      "1    GA        [100.0, 0, 0]\n",
      "2    GA        [100.0, 0, 0]\n",
      "3    GA        [100.0, 0, 0]\n",
      "4    GA        [100.0, 0, 0]\n",
      "..   ..                  ...\n",
      "550  SA  [190.0, 31.0, 15.0]\n",
      "551  SA  [188.0, 29.0, 15.0]\n",
      "552  SA   [33.0, 13.0, 14.0]\n",
      "553  SA   [33.0, 13.0, 14.0]\n",
      "554  SA   [38.0, 15.0, 14.0]\n",
      "\n",
      "[555 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#CRIAR O VETOR COM 3 ELEMENTOS - VARIÁVEL DEPENDENTE\n",
    "\n",
    "def criar_vetor(row):\n",
    "    if row['MH'] == 'GA':\n",
    "        return [row['NUMGEN'], 0, 0]\n",
    "    elif row['MH'] == 'PSO':\n",
    "        return [row['NUMITERA'], row['NUMPART'], 0]\n",
    "    elif row['MH'] == 'SA':\n",
    "        return [row['SA_STOPCRIT'], row['NUMITERAK'], row['INITTEMP']]\n",
    "    elif row['MH'] == 'TS':\n",
    "        return [row['TS_STOPCRIT'], row['TABULISTLEN'], 0]\n",
    "    else:\n",
    "        return [0, 0, 0]  \n",
    "\n",
    "dados_problema['vetor_parametros'] = dados_problema.apply(criar_vetor, axis=1)\n",
    "print(dados_problema[['MH', 'vetor_parametros']])\n",
    "parametros = np.vstack(dados_problema['vetor_parametros'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8de125c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuição de MH no conjunto de TREINO:\n",
      "TS     38.659794\n",
      "SA     30.154639\n",
      "PSO    23.711340\n",
      "GA      7.474227\n",
      "Name: MH, dtype: float64\n",
      "\n",
      "Distribuição de MH no conjunto de TESTE:\n",
      "TS     38.922156\n",
      "SA     29.940120\n",
      "PSO    23.952096\n",
      "GA      7.185629\n",
      "Name: MH, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana Silva\\AppData\\Local\\Temp\\ipykernel_6544\\3638300307.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['OBJFUNC'] = X['OBJFUNC'].map({'Cmax': 0, 'WT': 1})\n"
     ]
    }
   ],
   "source": [
    "#COLOCAR AS META-HEURÍSTICAS COMO VALORES NUMÉRICOS - NECESSÁRIO EM ALGUMAS TÉCNICAS DE MACHINE LEARNING\n",
    "mh_map = {'GA': 0, 'PSO': 1, 'TS': 2, 'SA': 3}\n",
    "dados_problema['MH_encoded'] = dados_problema['MH'].map(mh_map)\n",
    "\n",
    "#VARIAVEIS INDEPENDENTES\n",
    "X = dados_problema[['MH_encoded','NJOBS', 'NMACHINES', 'CMAXOPT', 'OBJFUNC']]\n",
    "\n",
    "#COLUNA OBJFUNX: PASSAR CMAX = 0 E WT=1 - NECESSÁRIO EM ALGUMAS TÉCNICAS DE MACHINE LEARNING\n",
    "X['OBJFUNC'] = X['OBJFUNC'].map({'Cmax': 0, 'WT': 1})\n",
    "\n",
    "#VARIÉVEL DEPENDENTE \n",
    "Y = parametros\n",
    "\n",
    "\n",
    "#DIVISÃO EM TREINO E TESTE - DIVISÃO ESTRATIFICADA POR MH\n",
    "X_train, X_test, Y_train, Y_test, strat_train, strat_test = train_test_split(\n",
    "    X, Y, dados_problema['MH'], \n",
    "    test_size=0.3, random_state=42, stratify=dados_problema['MH']\n",
    ")\n",
    "\n",
    "#PERCENTAGENS DE CADA MH NO CONJUNTO DE TREINO E TESTE - VERIFICA QUE A DIVISÃO ESTRATIFICADA FOI REALIZADA DE FORMA CORRETA\n",
    "print(\"Distribuição de MH no conjunto de TREINO:\")\n",
    "print(strat_train.value_counts(normalize=True) * 100)\n",
    "print(\"\\nDistribuição de MH no conjunto de TESTE:\")\n",
    "print(strat_test.value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0eeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'estimator__criterion': 'squared_error', 'estimator__max_depth': 5, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 5}\n",
      "\n",
      "\n",
      "Métricas de Avaliação:\n",
      "MSE: 3557.0479\n",
      "RMSE: 59.6410\n",
      "MAE: 11.7545\n",
      "R²: 0.9762\n",
      "\n",
      "MAPE por Parâmetro:\n",
      "Parâmetro 1: 4.50%\n",
      "Parâmetro 2: 3.60%\n",
      "Parâmetro 3: 0.14%\n",
      "MAPE Geral: 2.75%\n",
      "\n",
      "Importância das Features por Parâmetro:\n",
      "\n",
      "Parâmetro 1:\n",
      "  MH_encoded: 0.7977\n",
      "  NJOBS: 0.1938\n",
      "  NMACHINES: 0.0000\n",
      "  CMAXOPT: 0.0057\n",
      "  OBJFUNC: 0.0027\n",
      "\n",
      "Parâmetro 2:\n",
      "  MH_encoded: 0.7808\n",
      "  NJOBS: 0.0570\n",
      "  NMACHINES: 0.0000\n",
      "  CMAXOPT: 0.1622\n",
      "  OBJFUNC: 0.0000\n",
      "\n",
      "Parâmetro 3:\n",
      "  MH_encoded: 1.0000\n",
      "  NJOBS: 0.0000\n",
      "  NMACHINES: 0.0000\n",
      "  CMAXOPT: 0.0000\n",
      "  OBJFUNC: 0.0000\n",
      "\n",
      "Importância Geral das Features (Média entre os parâmetros):\n",
      "  MH_encoded: 0.8595\n",
      "  NJOBS: 0.0836\n",
      "  NMACHINES: 0.0000\n",
      "  CMAXOPT: 0.0560\n",
      "  OBJFUNC: 0.0009\n"
     ]
    }
   ],
   "source": [
    "#ÁRVORE DE DECISÃO ---------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#GARANTIR OS ZEROS NAS POSIÇÕES DO VETOR PARA CADA META-HEURÍSTICA \n",
    "def corrigir_predicao(mh, vetor_predito):\n",
    "    vetor_predito = np.round(vetor_predito).astype(int)\n",
    "    if mh == 'GA':\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = 0\n",
    "        vetor_predito[2] = 0\n",
    "    elif mh in ['TS', 'PSO']:\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = max(vetor_predito[1], 1)\n",
    "        vetor_predito[2] = 0\n",
    "    elif mh == 'SA':\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = max(vetor_predito[1], 1)\n",
    "        vetor_predito[2] = max(vetor_predito[2], 1)\n",
    "    return vetor_predito.tolist()\n",
    "\n",
    "#CRIAR MODELO ÁRVORE DE DECISÃO\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "multi_output_regressor = MultiOutputRegressor(dt_regressor)\n",
    "\n",
    "#DEFINIR PARÂMETROS \n",
    "param_grid = {\n",
    "    'estimator__criterion': ['squared_error', 'absolute_error'], \n",
    "    'estimator__max_depth': [3, 5, 10, 15, 20, None],\n",
    "    'estimator__min_samples_split': [2, 5, 10, 15],\n",
    "    'estimator__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 10, 15]\n",
    "}\n",
    "\n",
    "#GRIDSEARCH COM VALIDAÇÃO CRUZADA\n",
    "grid_search = GridSearchCV(\n",
    "    multi_output_regressor, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1\n",
    "    )\n",
    "\n",
    "#TREINAR O MODELO À PROCURA DOS MELHOR HIPERPARÂMETROS\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "#OBTER O MELHOR MODELO\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Melhores parâmetros: {grid_search.best_params_}\\n\")\n",
    "\n",
    "#PREVISÕES\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "#APLICAR A \"CORREÇÃO\"\n",
    "Y_pred_corrigido = []\n",
    "for mh, pred, real in zip(strat_test, Y_pred, Y_test):\n",
    "    corrigido = corrigir_predicao(mh, pred)\n",
    "    Y_pred_corrigido.append(corrigido)\n",
    "    #print(f\"MH: {mh} | Real: {real.tolist()} | Previsto: {corrigido}\")\n",
    "\n",
    "#CÁLCULAR MÉTRICAS DE AVALIAÇÃO\n",
    "mse = mean_squared_error(Y_test, Y_pred_corrigido)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_corrigido)\n",
    "r2 = r2_score(Y_test, Y_pred_corrigido)\n",
    "\n",
    "print(\"\\nMétricas de Avaliação:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "#PARA O CÁLCULO DO MAPE - IGNORA AS DIVISÕES POR ZERO \n",
    "Y_test_np = np.array(Y_test)\n",
    "Y_pred_corrigido_np = np.array(Y_pred_corrigido)\n",
    "mape_por_parametro = []\n",
    "for i in range(Y_test_np.shape[1]):\n",
    "    y_true = Y_test_np[:, i]\n",
    "    y_pred = Y_pred_corrigido_np[:, i]\n",
    "    mask = y_true != 0  \n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan  #SE TODOS FOREM ZERO, NÃO CALCULA \n",
    "    mape_por_parametro.append(mape)\n",
    "mape_geral = np.nanmean(mape_por_parametro)     #MÉDIA\n",
    "print(\"\\nMAPE por Parâmetro:\")\n",
    "for i, mape_val in enumerate(mape_por_parametro):\n",
    "    print(f\"Parâmetro {i+1}: {mape_val:.2f}%\")\n",
    "print(f\"MAPE Geral: {mape_geral:.2f}%\")\n",
    "\n",
    "#IMPORTANCIA DAS FEATURES - COLOCA NUM EXCEL POR PARÂMETRO (CADA POSIÇÃO DO VETOR É UM PARÂMETRO) E NOUTRO O GERAL \n",
    "print(\"\\nImportância das Features por Parâmetro:\")\n",
    "feature_importances = []\n",
    "feature_names = X_train.columns\n",
    "df_importancias_por_parametro = pd.DataFrame()\n",
    "for i, estimator in enumerate(best_model.estimators_):\n",
    "    importance = estimator.feature_importances_\n",
    "    feature_importances.append(importance)\n",
    "    #CRIAR UMA COLUNA POR PARÂMETRO\n",
    "    df_importancias_por_parametro[f'Parâmetro_{i+1}'] = pd.Series(importance, index=feature_names)\n",
    "    print(f\"\\nParâmetro {i+1}:\")\n",
    "    for name, imp in zip(feature_names, importance):\n",
    "        print(f\"  {name}: {imp:.4f}\")\n",
    "#ARREDONDAR A 4 CASAS DECIMAIS \n",
    "df_importancias_por_parametro = df_importancias_por_parametro.round(4)\n",
    "df_importancias_por_parametro.to_excel(\"importancia_por_parametro.xlsx\", index=True)\n",
    "feature_importances = np.array(feature_importances)\n",
    "importance_geral = np.mean(feature_importances, axis=0)\n",
    "df_importancia_geral = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importância_Média\": np.round(importance_geral, 4)\n",
    "})\n",
    "df_importancia_geral.to_excel(\"importancia_geral.xlsx\", index=False)\n",
    "print(\"\\nImportância Geral das Features (Média entre os parâmetros):\")\n",
    "for name, imp in zip(feature_names, importance_geral):\n",
    "    print(f\"  {name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e46d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'estimator__max_depth': 5, 'estimator__max_features': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 400}\n",
      "\n",
      "\n",
      "Métricas de Avaliação:\n",
      "MSE: 3515.9281\n",
      "RMSE: 59.2953\n",
      "MAE: 12.0319\n",
      "R²: 0.9766\n",
      "\n",
      "MAPE por Parâmetro:\n",
      "Parâmetro 1: 4.79%\n",
      "Parâmetro 2: 4.35%\n",
      "Parâmetro 3: 0.14%\n",
      "MAPE Geral: 3.09%\n",
      "\n",
      "Importância das Features por Parâmetro:\n",
      "\n",
      "Parâmetro 1:\n",
      "  MH_encoded: 0.7962\n",
      "  NJOBS: 0.1773\n",
      "  NMACHINES: 0.0003\n",
      "  CMAXOPT: 0.0251\n",
      "  OBJFUNC: 0.0011\n",
      "\n",
      "Parâmetro 2:\n",
      "  MH_encoded: 0.7794\n",
      "  NJOBS: 0.1144\n",
      "  NMACHINES: 0.0001\n",
      "  CMAXOPT: 0.1029\n",
      "  OBJFUNC: 0.0033\n",
      "\n",
      "Parâmetro 3:\n",
      "  MH_encoded: 1.0000\n",
      "  NJOBS: 0.0000\n",
      "  NMACHINES: 0.0000\n",
      "  CMAXOPT: 0.0000\n",
      "  OBJFUNC: 0.0000\n",
      "\n",
      "Importância Geral das Features (Média entre os parâmetros):\n",
      "  MH_encoded: 0.8585\n",
      "  NJOBS: 0.0972\n",
      "  NMACHINES: 0.0001\n",
      "  CMAXOPT: 0.0427\n",
      "  OBJFUNC: 0.0015\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST ------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#GARANTIR OS ZEROS NAS POSIÇÕES DO VETOR PARA CADA META-HEURÍSTICA  \n",
    "def corrigir_predicao(mh, vetor_predito):\n",
    "    vetor_predito = np.round(vetor_predito).astype(int)\n",
    "    if mh == 'GA':\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = 0\n",
    "        vetor_predito[2] = 0\n",
    "    elif mh in ['TS', 'PSO']:\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = max(vetor_predito[1], 1)\n",
    "        vetor_predito[2] = 0\n",
    "    elif mh == 'SA':\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = max(vetor_predito[1], 1)\n",
    "        vetor_predito[2] = max(vetor_predito[2], 1)\n",
    "    return vetor_predito.tolist()\n",
    "\n",
    "#CRIAR MODELO DE RANDOM FOREST\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "multi_output_regressor = MultiOutputRegressor(rf_regressor)\n",
    "\n",
    "#DEFINIR PARÂMETROS\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200, 300, 400],\n",
    "    'estimator__max_depth': [3, 5, 7, 10, 20, 30, None],\n",
    "    'estimator__min_samples_split': [2, 5, 10, 15],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4, 6],\n",
    "    'estimator__max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "#GRIDSEARCH COM VALIDAÇÃO CRUZADA\n",
    "grid_search = GridSearchCV(\n",
    "    multi_output_regressor, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#TREINAR O MODELO À PROCURA DOS MELHOR HIPERPARÂMETROS\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "#OBTER O MELHOR MODELO\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Melhores parâmetros: {grid_search.best_params_}\\n\")\n",
    "\n",
    "#PREVISÕES\n",
    "Y_pred = best_model.predict(X_test)\n",
    "\n",
    "#APLICAR A \"CORREÇÃO\"\n",
    "Y_pred_corrigido = []\n",
    "for mh, pred in zip(strat_test, Y_pred):\n",
    "    Y_pred_corrigido.append(corrigir_predicao(mh, pred))\n",
    "    #print(f\"MH: {mh} | Real: {real.tolist()} | Previsto: {corrigido}\") \n",
    "\n",
    "#CÁLCULAR AS MÉTRICAS DE AVALIAÇÃO \n",
    "mse = mean_squared_error(Y_test, Y_pred_corrigido)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_corrigido)\n",
    "r2 = r2_score(Y_test, Y_pred_corrigido)\n",
    "\n",
    "print(\"\\nMétricas de Avaliação:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "#PARA O CÁLCULO DO MAPE - IGNORA AS DIVISÕES POR ZERO \n",
    "Y_test_np = np.array(Y_test)\n",
    "Y_pred_corrigido_np = np.array(Y_pred_corrigido)\n",
    "mape_por_parametro = []\n",
    "for i in range(Y_test_np.shape[1]):\n",
    "    y_true = Y_test_np[:, i]\n",
    "    y_pred = Y_pred_corrigido_np[:, i]\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    mape_por_parametro.append(mape)\n",
    "mape_geral = np.nanmean(mape_por_parametro)\n",
    "print(\"\\nMAPE por Parâmetro:\")\n",
    "for i, mape_val in enumerate(mape_por_parametro):\n",
    "    print(f\"Parâmetro {i+1}: {mape_val:.2f}%\")\n",
    "print(f\"MAPE Geral: {mape_geral:.2f}%\")\n",
    "\n",
    "#IMPORTANCIA DAS FEATURES - COLOCA NUM EXCEL POR PARÂMETRO (CADA POSIÇÃO DO VETOR É UM PARÂMETRO) E NOUTRO O GERAL \n",
    "print(\"\\nImportância das Features por Parâmetro:\")\n",
    "feature_importances = []\n",
    "feature_names = X_train.columns\n",
    "df_importancias_por_parametro = pd.DataFrame()\n",
    "for i, estimator in enumerate(best_model.estimators_):\n",
    "    importance = estimator.feature_importances_\n",
    "    feature_importances.append(importance)\n",
    "    #CRIAR UMA COLUNA POR PARÂMETRO\n",
    "    df_importancias_por_parametro[f'Parâmetro_{i+1}'] = pd.Series(importance, index=feature_names)\n",
    "    print(f\"\\nParâmetro {i+1}:\")\n",
    "    for name, imp in zip(feature_names, importance):\n",
    "        print(f\"  {name}: {imp:.4f}\")\n",
    "#ARREDONDAR A 4 CASAS DECIMAIS \n",
    "df_importancias_por_parametro = df_importancias_por_parametro.round(4)\n",
    "df_importancias_por_parametro.to_excel(\"importancia_por_parametro.xlsx\", index=True)\n",
    "feature_importances = np.array(feature_importances)\n",
    "importance_geral = np.mean(feature_importances, axis=0)\n",
    "df_importancia_geral = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importância_Média\": np.round(importance_geral, 4)\n",
    "})\n",
    "df_importancia_geral.to_excel(\"importancia_geral.xlsx\", index=False)\n",
    "print(\"\\nImportância Geral das Features (Média entre os parâmetros):\")\n",
    "for name, imp in zip(feature_names, importance_geral):\n",
    "    print(f\"  {name}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8575779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Métricas de Avaliação:\n",
      "MSE: 134857.3693\n",
      "RMSE: 367.2293\n",
      "MAE: 142.7425\n",
      "R²: 0.4582\n",
      "\n",
      "MAPE por Parâmetro:\n",
      "Parâmetro 1: 204.35%\n",
      "Parâmetro 2: 519.97%\n",
      "Parâmetro 3: 25.76%\n",
      "MAPE Geral: 250.03%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#IMPORTANCIA DAS FEATURES - COLOCA NUM EXCEL\\nprint(\"\\nImportância das Features por Parâmetro:\")\\nfeature_importances = []\\nfeature_names = X_train.columns\\ndf_importancias_por_parametro = pd.DataFrame()\\n\\nfor i, estimator in enumerate(best_model.estimators_):\\n    importance = estimator.feature_importances_\\n    feature_importances.append(importance)\\n\\n    #CRIAR UMA COLUNA POR PARÂMETRO\\n    df_importancias_por_parametro[f\\'Parâmetro_{i+1}\\'] = pd.Series(importance, index=feature_names)\\n    print(f\"\\nParâmetro {i+1}:\")\\n    for name, imp in zip(feature_names, importance):\\n        print(f\"  {name}: {imp:.4f}\")\\n\\n#ARREDONDAR A 4 CASAS DECIMAIS \\ndf_importancias_por_parametro = df_importancias_por_parametro.round(4)\\ndf_importancias_por_parametro.to_excel(\"importancia_por_parametro.xlsx\", index=True)\\nfeature_importances = np.array(feature_importances)\\nimportance_geral = np.mean(feature_importances, axis=0)\\n\\ndf_importancia_geral = pd.DataFrame({\\n    \"Feature\": feature_names,\\n    \"Importância_Média\": np.round(importance_geral, 4)\\n})\\n\\ndf_importancia_geral.to_excel(\"importancia_geral.xlsx\", index=False)\\nprint(\"\\nImportância Geral das Features (Média entre os parâmetros):\")\\nfor name, imp in zip(feature_names, importance_geral):\\n    print(f\"  {name}: {imp:.4f}\")'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REGRESSÃO LINEAR ---------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#GARANTIR OS ZEROS NAS POSIÇÕES DO VETOR PARA CADA META-HEURÍSTICA  \n",
    "def corrigir_predicao(mh, vetor_predito):\n",
    "    vetor_predito = np.round(vetor_predito).astype(int)\n",
    "    if mh == 'GA':\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = 0\n",
    "        vetor_predito[2] = 0\n",
    "    elif mh in ['TS', 'PSO']:\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = max(vetor_predito[1], 1)\n",
    "        vetor_predito[2] = 0\n",
    "    elif mh == 'SA':\n",
    "        vetor_predito[0] = max(vetor_predito[0], 1)\n",
    "        vetor_predito[1] = max(vetor_predito[1], 1)\n",
    "        vetor_predito[2] = max(vetor_predito[2], 1)\n",
    "    return vetor_predito.tolist()\n",
    "\n",
    "#CRIAR MODELO DE REGRESSÃO LINEAR \n",
    "lr = LinearRegression()\n",
    "multi_output_regressor = MultiOutputRegressor(lr)\n",
    "\n",
    "#TREINAR O MODELO \n",
    "multi_output_regressor.fit(X_train, Y_train)\n",
    "\n",
    "#PREVISÕES\n",
    "Y_pred = multi_output_regressor.predict(X_test)\n",
    "\n",
    "#APLICAR \"CORREÇÃO\"\n",
    "Y_pred_corrigido = []\n",
    "for mh, pred in zip(strat_test, Y_pred):\n",
    "    Y_pred_corrigido.append(corrigir_predicao(mh, pred))\n",
    "    #print(f\"MH: {mh} | Real: {real.tolist()} | Previsto: {corrigido}\") \n",
    "\n",
    "#CALCULAR MÉTRICAS DE AVALIAÇÃO\n",
    "mse = mean_squared_error(Y_test, Y_pred_corrigido)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(Y_test, Y_pred_corrigido)\n",
    "r2 = r2_score(Y_test, Y_pred_corrigido)\n",
    "\n",
    "print(\"\\nMétricas de Avaliação:\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "#PARA O CÁLCULO DO MAPE - IGNORA AS DIVISÕES POR ZERO \n",
    "Y_test_np = np.array(Y_test)\n",
    "Y_pred_corrigido_np = np.array(Y_pred_corrigido)\n",
    "mape_por_parametro = []\n",
    "for i in range(Y_test_np.shape[1]):\n",
    "    y_true = Y_test_np[:, i]\n",
    "    y_pred = Y_pred_corrigido_np[:, i]\n",
    "    mask = y_true != 0\n",
    "    if np.any(mask):\n",
    "        mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    mape_por_parametro.append(mape)\n",
    "mape_geral = np.nanmean(mape_por_parametro)\n",
    "print(\"\\nMAPE por Parâmetro:\")\n",
    "for i, mape_val in enumerate(mape_por_parametro):\n",
    "    print(f\"Parâmetro {i+1}: {mape_val:.2f}%\")\n",
    "print(f\"MAPE Geral: {mape_geral:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
