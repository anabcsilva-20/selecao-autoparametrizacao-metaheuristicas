{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1858fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      MH  NJOBS  NMACHINES  CMAXOPT OBJFUNC  CMAX  TIMEEXEC  NUMPART  NUMITERA\n",
      "0    PSO      6          6       55    Cmax    59      0.24       15       500\n",
      "1    PSO      6          6       55    Cmax    59      0.28       15       536\n",
      "2    PSO      6          6       55    Cmax    60      0.25       15       484\n",
      "3    PSO      6          6       55    Cmax    60      0.25       15       437\n",
      "4    PSO     10         10      887      WT  1455      1.25       25      1000\n",
      "..   ...    ...        ...      ...     ...   ...       ...      ...       ...\n",
      "127  PSO     30         10     1784      WT  2158     11.56       36      1934\n",
      "128  PSO     30         10     1784      WT  2187     12.33       36      2121\n",
      "129  PSO     50         10     2852      WT  2968     77.76       76      3025\n",
      "130  PSO     50         10     2924      WT  3153     78.53       76      3030\n",
      "131  PSO     50         10     2843      WT  3458     44.04      100      4000\n",
      "\n",
      "[132 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "#MODELO PREDITIVO INDIVIDUAL PARA O TABU SEARCH E PARTICLE SWARM OPTIMIZATION - MODELO DE REGRESSÃO DE AFINAÇÃO DOS PARÂMETROS ---------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "import xlwings as xw\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "#EXCEL - CAMINHO DO FICHEIRO - COLOCAR DATASET RELATIVO AO TABU SEARCH OU PARTICLE SWARM OPTIMIZATION (ESTÁ COM FICHEIRO DE PARTICLE SWARM OPTIMIZATION)\n",
    "#NOTA: O MODELO INDIVIDUAL REALIZADO SERÁ PARA O PARTICLE SWARM OPTIMIZATION, SE QUISER O TABU SEACH MUDAR O FICHEIRO EXCEL PARA DataSet_Regressão_TS\n",
    "file_path = r\"D:\\Documentos\\...\\DataSet_Regressão_PSO.xlsx\"\n",
    "dados_problema= pd.read_excel(file_path)\n",
    "print (dados_problema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c294458",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIVIDIR DADOS EM TREINO E TESTE (RETIRAR COLONA CMAX, MH E TIMEEXEC (NÃO É UMA FEATURE))\n",
    "dados_problema=dados_problema.drop(columns=['CMAX'])\n",
    "dados_problema=dados_problema.drop(columns=['MH'])\n",
    "dados_problema=dados_problema.drop(columns=['TIMEEXEC'])\n",
    "#print (dados_problema)\n",
    "\n",
    "#VARIÁVEIS INDEPENDENTES\n",
    "X = dados_problema.drop(columns=['NUMPART', 'NUMITERA'])      #PARA TABU SEARCH É X = dados_problema.drop(columns=['TABULISTLEN', 'TS_STOPCRIT'])\n",
    "#VARIÁVEL DEPENDENTE\n",
    "y = dados_problema[['NUMPART', 'NUMITERA']]          #PARA TABU SEARCH É y = dados_problema[['TABULISTLEN', 'TS_STOPCRIT']] \n",
    "\n",
    "#COLUNA OBJFUNX: PASSAR CMAX = 0 E WT=1 - NECESSÁRIO EM ALGUMAS TÉCNICAS\n",
    "X['OBJFUNC'] = X['OBJFUNC'].map({'Cmax': 0, 'WT': 1})\n",
    "\n",
    "#DIVIDIR OS DADOS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5bbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores Hiperparâmetros: {'estimator__criterion': 'squared_error', 'estimator__max_depth': 3, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 10}\n",
      "\n",
      "=== RESULTADO GERAL (MÉDIA TESTE) ===\n",
      "MSE: 31196.1483\n",
      "RMSE: 176.6243\n",
      "MAE: 69.5098\n",
      "MAPE: 8.16%\n",
      "R²: 0.6452\n",
      "\n",
      "=== Importância das Features (Média entre os modelos, normalizada) ===\n",
      "     Feature  Importance\n",
      "0      NJOBS      0.9874\n",
      "2    CMAXOPT      0.0066\n",
      "3    OBJFUNC      0.0060\n",
      "1  NMACHINES      0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#COMPARAÇÃO ENTRE TREINO E TESTE\\ncomparison_df = pd.DataFrame({\\n    \\'Variável\\': [\\'NJOBS\\', \\'NMACHINES\\', \\'MÉDIA GERAL\\'],\\n    \\'MSE Treino\\': list(mse_train) + [np.mean(mse_train)],\\n    \\'MSE Teste\\': list(mse_test) + [mse_test_mean],\\n    \\'RMSE Treino\\': list(rmse_train) + [np.mean(rmse_train)],\\n    \\'RMSE Teste\\': list(rmse_test) + [rmse_test_mean],\\n    \\'MAE Treino\\': list(mae_train) + [np.mean(mae_train)],\\n    \\'MAE Teste\\': list(mae_test) + [mae_test_mean],\\n    \\'MAPE Treino\\': list(mape_train) + [np.mean(mape_train)],\\n    \\'MAPE Teste\\': list(mape_test) + [mape_test_mean],\\n    \\'R² Treino\\': list(r2_train) + [np.mean(r2_train)],\\n    \\'R² Teste\\': list(r2_test) + [r2_test_mean]\\n})\\n\\nprint(\"\\n=== QUADRO COMPARATIVO TREINO vs TESTE ===\")\\nprint(comparison_df.round(4))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ÁRVORE DE DECISÃO ------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#FUNÇÃO PARA CALCULAR MÉTRICAS DE AVALIAÇÃO\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true), axis=0) * 100\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "#CRIAR MODELO ÁRVORE DE DESIÇÃO\n",
    "base_model = DecisionTreeRegressor(random_state=42)\n",
    "model = MultiOutputRegressor(base_model)\n",
    "\n",
    "# DEFINIIR PARÂMETROS\n",
    "param_grid = {\n",
    "    'estimator__criterion': ['squared_error', 'absolute_error'],\n",
    "    'estimator__max_depth': [3, 5, 10, 15, 20, None],\n",
    "    'estimator__min_samples_split': [2, 5, 10, 15],\n",
    "    'estimator__min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 10, 15]\n",
    "}\n",
    "\n",
    "#GRIDSEARCH COM VALIDAÇÃO CRUZADA \n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#TREINAR O MODELO À PROCURA DOS MELHORES HIPERPARÂMETROS\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#OBTER MELHOR MODELO\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nMelhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "#PREVISÃO E CALCULO DAS MÉTRICAS DE AVALIAÇÃO\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "mse_test, rmse_test, mae_test, mape_test, r2_test = evaluate_metrics(y_test, y_test_pred)\n",
    "\n",
    "\n",
    "'''\n",
    "#RESULTADOS DAS MÉTRICAS DE AVALIAÇÃO DE CADA VARIÁVEL DEPENDENTE\n",
    "print(\"=== Resultados no CONJUNTO DE TESTE ===\")\n",
    "for i, target in enumerate(['NUMPART', 'NUMITERA']):        #PARA TABU SEARCH É (['TABULISTLEN', 'TS_STOPCRIT'])\n",
    "    print(f\"\\nVariável: {target}\")\n",
    "    print(f\"MSE: {mse_test[i]:.4f}\")\n",
    "    print(f\"RMSE: {rmse_test[i]:.4f}\")\n",
    "    print(f\"MAE: {mae_test[i]:.4f}\")\n",
    "    print(f\"MAPE: {mape_test[i]:.2f}%\")\n",
    "    print(f\"R²: {r2_test[i]:.4f}\")\n",
    "'''\n",
    "\n",
    "#RESULTADOS GERAIS - MÉDIA DOS RESULTADOS DAS DUAS VARIÁVEIS (À EXCEÇÃO DO RMSE) \n",
    "mse_test_mean = np.mean(mse_test)\n",
    "rmse_test_mean = np.sqrt(mse_test_mean)\n",
    "mae_test_mean = np.mean(mae_test)\n",
    "mape_test_mean = np.mean(mape_test)\n",
    "r2_test_mean = np.mean(r2_test)\n",
    "\n",
    "print(\"\\n=== RESULTADO GERAL (MÉDIA TESTE) ===\")\n",
    "print(f\"MSE: {mse_test_mean:.4f}\")\n",
    "print(f\"RMSE: {rmse_test_mean:.4f}\")\n",
    "print(f\"MAE: {mae_test_mean:.4f}\")\n",
    "print(f\"MAPE: {mape_test_mean:.2f}%\")\n",
    "print(f\"R²: {r2_test_mean:.4f}\")\n",
    "\n",
    "\n",
    "#IMPORTANCIA DAS FEATURES\n",
    "#CALCULAR A MÉDIA DA IMPORTÂNCIA DE CADA VARIAVEL DEPENDENTE (CADA ÁRVORE DE DECISÃO)\n",
    "importances_raw = np.mean([est.feature_importances_ for est in best_model.estimators_], axis=0)\n",
    "importances = importances_raw / importances_raw.sum()\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "importance_df['Importance'] = importance_df['Importance'].round(4)\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\n=== Importância das Features (Média entre os modelos, normalizada) ===\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f674220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melhores Hiperparâmetros: {'estimator__max_depth': 3, 'estimator__max_features': None, 'estimator__min_samples_leaf': 1, 'estimator__min_samples_split': 5, 'estimator__n_estimators': 50}\n",
      "\n",
      "=== RESULTADO GERAL (MÉDIA TESTE) ===\n",
      "MSE: 29454.3671\n",
      "RMSE: 171.6227\n",
      "MAE: 67.1109\n",
      "MAPE: 7.75%\n",
      "R²: 0.6915\n",
      "\n",
      "=== Importância das Features ===\n",
      "     Feature  Importance\n",
      "0      NJOBS      0.5975\n",
      "2    CMAXOPT      0.3928\n",
      "3    OBJFUNC      0.0094\n",
      "1  NMACHINES      0.0003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Comparação Treino x Teste (tabela resumo)\\ncomparison_df = pd.DataFrame({\\n    \\'Variável\\': [\\'NJOBS\\', \\'NMACHINES\\', \\'MÉDIA GERAL\\'],\\n    \\'MSE Treino\\': list(mse_train) + [np.mean(mse_train)],\\n    \\'MSE Teste\\': list(mse_test) + [mse_test_mean],\\n    \\'RMSE Treino\\': list(rmse_train) + [np.mean(rmse_train)],\\n    \\'RMSE Teste\\': list(rmse_test) + [rmse_test_mean],\\n    \\'MAE Treino\\': list(mae_train) + [np.mean(mae_train)],\\n    \\'MAE Teste\\': list(mae_test) + [mae_test_mean],\\n    \\'MAPE Treino\\': list(mape_train) + [np.mean(mape_train)],\\n    \\'MAPE Teste\\': list(mape_test) + [mape_test_mean],\\n    \\'R² Treino\\': list(r2_train) + [np.mean(r2_train)],\\n    \\'R² Teste\\': list(r2_test) + [r2_test_mean]\\n})\\n\\nprint(\"\\n=== QUADRO COMPARATIVO TREINO vs TESTE (Random Forest) ===\")\\nprint(comparison_df.round(4))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RANDOM FOREST ------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#FUNÇÃO PARA CALCULAR AS MÉTRICAS DE AVALIAÇÃO\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true), axis=0) * 100\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "#CRIAR MODELO RANDOM FOREST\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "model = MultiOutputRegressor(base_model)\n",
    "\n",
    "#DEFINIR PARÂMETROS\n",
    "param_grid = {\n",
    "    'estimator__n_estimators': [50, 100, 200, 300, 400],\n",
    "    'estimator__max_depth': [None, 3, 5, 7, 10, 20, 30],\n",
    "    'estimator__min_samples_split': [2, 5, 10, 15],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4, 6],\n",
    "    'estimator__max_features': [None, 'sqrt', 'log2'],\n",
    "}\n",
    "\n",
    "#GRIDSEACH COM VALIDAÇÃO CRUZADAS\n",
    "grid_search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "#TREINAR O MODELO À PROCURA DOS MELHORES HIPERPARÂMETROS\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#OBTER O MELHOR MODELO \n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nMelhores Hiperparâmetros:\", grid_search.best_params_)\n",
    "\n",
    "#PREVISÃO E CALCULO DAS MÉTRICAS DE AVALIAÇÃO\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "mse_test, rmse_test, mae_test, mape_test, r2_test = evaluate_metrics(y_test, y_test_pred)\n",
    "\n",
    "'''\n",
    "#RESULTADOS DAS MÉTRICAS DE AVALIAÇÃO DE CADA VARIÁVEL DEPENDENTE\n",
    "print(\"=== Resultados no CONJUNTO DE TESTE (Random Forest) ===\")\n",
    "for i, target in enumerate(['NUMPART', 'NUMITERA']):             #PARA TABU SEARCH É (['TABULISTLEN', 'TS_STOPCRIT'])\n",
    "    print(f\"\\nVariável: {target}\")\n",
    "    print(f\"MSE: {mse_test[i]:.4f}\")\n",
    "    print(f\"RMSE: {rmse_test[i]:.4f}\")\n",
    "    print(f\"MAE: {mae_test[i]:.4f}\")\n",
    "    print(f\"MAPE: {mape_test[i]:.2f}%\")\n",
    "    print(f\"R²: {r2_test[i]:.4f}\")\n",
    "'''\n",
    "\n",
    "#RESULTADOS GERAIS - MÉDIA DOS RESULTADOS DAS DUAS VARIÁVEIS (À EXCEÇÃO DO RMSE)\n",
    "mse_test_mean = np.mean(mse_test)\n",
    "rmse_test_mean = np.sqrt(mse_test_mean)\n",
    "mae_test_mean = np.mean(mae_test)\n",
    "mape_test_mean = np.mean(mape_test)\n",
    "r2_test_mean = np.mean(r2_test)\n",
    "\n",
    "print(\"\\n=== RESULTADO GERAL (MÉDIA TESTE) ===\")\n",
    "print(f\"MSE: {mse_test_mean:.4f}\")\n",
    "print(f\"RMSE: {rmse_test_mean:.4f}\")\n",
    "print(f\"MAE: {mae_test_mean:.4f}\")\n",
    "print(f\"MAPE: {mape_test_mean:.2f}%\")\n",
    "print(f\"R²: {r2_test_mean:.4f}\")\n",
    "\n",
    "#IMPORTANCIA DAS FEATURES\n",
    "#CALCULAR A MÉDIA DA IMPORTÂNCIA DE CADA VARIAVEL DEPENDENTE \n",
    "importances = np.mean([est.feature_importances_ for est in best_model.estimators_], axis=0)\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "})\n",
    "importance_df['Importance'] = importance_df['Importance'].round(4)\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "print(\"\\n=== Importância das Features ===\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82640cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADO GERAL (MÉDIA TESTE) ===\n",
      "MSE: 41052.8317\n",
      "RMSE: 202.6150\n",
      "MAE: 117.4866\n",
      "MAPE: 13.96%\n",
      "R²: 0.5558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Comparação Treino x Teste (tabela resumo)\\ncomparison_df = pd.DataFrame({\\n    \\'Variável\\': [\\'NJOBS\\', \\'NMACHINES\\', \\'MÉDIA GERAL\\'],\\n    \\'MSE Treino\\': list(mse_train) + [np.mean(mse_train)],\\n    \\'MSE Teste\\': list(mse_test) + [mse_test_mean],\\n    \\'RMSE Treino\\': list(rmse_train) + [np.mean(rmse_train)],\\n    \\'RMSE Teste\\': list(rmse_test) + [rmse_test_mean],\\n    \\'MAE Treino\\': list(mae_train) + [np.mean(mae_train)],\\n    \\'MAE Teste\\': list(mae_test) + [mae_test_mean],\\n    \\'MAPE Treino\\': list(mape_train) + [np.mean(mape_train)],\\n    \\'MAPE Teste\\': list(mape_test) + [mape_test_mean],\\n    \\'R² Treino\\': list(r2_train) + [np.mean(r2_train)],\\n    \\'R² Teste\\': list(r2_test) + [r2_test_mean]\\n})\\n\\nprint(\"\\n=== QUADRO COMPARATIVO TREINO vs TESTE (Regressão Linear Simples) ===\")\\nprint(comparison_df.round(4))'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REGRESSÃO LINEAR ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#FUNÇÃO PARA CALCULAR AS MÉTRICAS DE AVALIAÇÃO\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true), axis=0) * 100\n",
    "    r2 = r2_score(y_true, y_pred, multioutput='raw_values')\n",
    "    return mse, rmse, mae, mape, r2\n",
    "\n",
    "#CRIAR MODELO DE REGRESSÃO LINEAR\n",
    "base_model = LinearRegression()\n",
    "model = MultiOutputRegressor(base_model)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#PREVISÕES\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "#CALCULAR MÉTRICAS DE AVALIAÇÃO\n",
    "mse_test, rmse_test, mae_test, mape_test, r2_test = evaluate_metrics(y_test, y_test_pred)\n",
    "\n",
    "'''\n",
    "#RESULTADOS DAS MÉTRICAS DE AVALIAÇÃO DE CADA VARIÁVEL DEPENDENTE\n",
    "print(\"=== Resultados no CONJUNTO DE TESTE ===\")\n",
    "for i, target in enumerate(['TABULISTLEN', 'TS_STOPCRIT']):     #PARA TABU SEARCH É (['TABULISTLEN', 'TS_STOPCRIT'])\n",
    "    print(f\"\\nVariável: {target}\")\n",
    "    print(f\"MSE: {mse_test[i]:.4f}\")\n",
    "    print(f\"RMSE: {rmse_test[i]:.4f}\")\n",
    "    print(f\"MAE: {mae_test[i]:.4f}\")\n",
    "    print(f\"MAPE: {mape_test[i]:.2f}%\")\n",
    "    print(f\"R²: {r2_test[i]:.4f}\")\n",
    "'''\n",
    "\n",
    "#RESULTADOS GERAIS - MÉDIA DOS RESULTADOS DAS DUAS VARIÁVEIS (À EXCEÇÃO DO RMSE)\n",
    "mse_test_mean = np.mean(mse_test)\n",
    "rmse_test_mean =  np.sqrt(mse_test_mean)\n",
    "mae_test_mean = np.mean(mae_test)\n",
    "mape_test_mean = np.mean(mape_test)\n",
    "r2_test_mean = np.mean(r2_test)\n",
    "\n",
    "print(\"\\n=== RESULTADO GERAL (MÉDIA TESTE) ===\")\n",
    "print(f\"MSE: {mse_test_mean:.4f}\")\n",
    "print(f\"RMSE: {rmse_test_mean:.4f}\")\n",
    "print(f\"MAE: {mae_test_mean:.4f}\")\n",
    "print(f\"MAPE: {mape_test_mean:.2f}%\")\n",
    "print(f\"R²: {r2_test_mean:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
